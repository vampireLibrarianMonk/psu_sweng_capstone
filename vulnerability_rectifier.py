import argparse
import os
import re
import sys
import yaml

import autoimport
from llama_cpp import Llama

from CodeExtractor import combine_files, create_main_method, write_combined_file
from utilities_llm import (setup_logger,
                           get_optimal_gpu_layers,
                           get_block_count_keys,
                           validate_iteration_allowance,
                           parse_python_script, run_mitigation_loop,
                           organize_imports_and_globals, write_to_file, process_streamed_output, extract_code_block,
                           extract_libraries, perform_scans, is_python_file, count_directories_in_path,
                           number_to_excel_column, create_chat_completion_llm, generate_import_statement,
                           get_methods_from_file, get_methods_with_signatures, prepend_to_file, execute_unit_test_file,
                           rename_file, validate_correction_limit, run_method_unit_test_creation_loop
                           )

mitigation_folder = "mitigated_files"

os.makedirs(mitigation_folder, exist_ok=True)

generated_unit_test_dir = "generated_unit_test"

os.makedirs(generated_unit_test_dir, exist_ok=True)

# Specify the path to your GGUF model file
model_path = "models/llama-3.2-3b-instruct-q8_0.gguf"

# Set up argument parser
parser = argparse.ArgumentParser(description='Process a Python file for vulnerability assessment.')
parser.add_argument('file_path', help='Path to the Python file to be analyzed.')
parser.add_argument('iteration_allowance', type=validate_iteration_allowance, help='Allowed number of '
                                                                                'mitigation runs (must be a positive'
                                                                                'integer).')
parser.add_argument('correction_limit', type=validate_correction_limit, help='Allowed number of unit test'
                                                                             'correction mitigation runs (must be a '
                                                                             'positive integer).')

# Parse command-line arguments
args = parser.parse_args()

input_file_path = args.file_path
iteration_allowance = args.iteration_allowance
correction_limit = args.correction_limit

# Get and separate file name into its base name and extension
base_name = os.path.basename(input_file_path)
name, ext = os.path.splitext(base_name)

# Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
parsed_script = parse_python_script(input_file_path)

new_parsed_script = {
    'methods': {}
}

# Get method count of parsed script
method_count = len(parsed_script['methods'].items())

# Define base name for mitigated files
mitigated_base_name = f"{name}_mitigated"

# Get the file count
file_count = count_directories_in_path(os.path.join(mitigation_folder, mitigated_base_name))

# Create folder for mitigated files
letter_conversion = number_to_excel_column(file_count)
mitigated_folder = os.path.join(mitigation_folder, mitigated_base_name, letter_conversion)

# Create the mitigated folder associated with the letter conversion
os.makedirs(mitigated_folder, exist_ok=True)

# Initialize the logger
logger = setup_logger(f"vulnerability_rectifier", letter_conversion, name)

# Load the YAML file
prompt_yaml = "config/prompt.yaml"
logger.info(f"Loading prompt configurations from {prompt_yaml}")
with open(prompt_yaml, 'r') as file:
    data = yaml.safe_load(file)

# Convert the prompts to a dictionary keyed by role
prompts_dict = {prompt['role']: prompt['content'] for prompt in data['prompts']}

# Extract the prompts directly into variables
mitigation_system_prompt = prompts_dict['mitigation_system_prompt']
mitigation_user_prompt = prompts_dict['mitigation_user_prompt']
refactor_script_system_prompt = prompts_dict['refactor_script_system_prompt']
refactor_script_user_prompt = prompts_dict['refactor_script_user_prompt']
unit_test_system_prompt = prompts_dict['unit_test_system_prompt']
unit_test_user_prompt = prompts_dict['unit_test_user_prompt']

# Vet the input file as a python script file
if is_python_file(input_file_path):
    with open(input_file_path, 'r') as file:
        original_code = file.read()
else:
    logger.error(f"{input_file_path} is not a valid Python file.")
    sys.exit(1)

# Alternative way for getting block count using Llama
# Load the model
# llm = Llama(model_path=model_path)

# Access the model's metadata
# metadata = llm.metadata

# Retrieve the block count
# total_layers = int(metadata.get('llama.block_count'))

# Get the total layers from the input model
total_layers = get_block_count_keys(model_path, logger)

# Determine the optimal number of GPU layers to offload
n_gpu_layers = get_optimal_gpu_layers(model_path, total_layers)

# Initialize the Llama model with appropriate settings
llm = Llama(
    model_path=model_path,
    seed=42,  # Fixed seed for reproducibility
    n_ctx=4096, #Set the desired context size here
    use_mmap=True,  # Memory mapping for efficiency
    use_mlock=True,  # Prevent swapping to disk for consistent performance
    n_gpu_layers=n_gpu_layers
)

# Only process the methods that
if parsed_script['methods']:
    logger.info(f"Processing parsed methods:")
    for method, method_code in parsed_script['methods'].items():
        # Mitigate Code
        new_code_block, passed_scans = run_mitigation_loop(
            mitigation_system_prompt,
            mitigation_user_prompt,
            iteration_allowance,
            base_name,
            llm,
            logger,
            mitigated_folder,
            mitigated_base_name,
            letter_conversion,
            method_code,
            method)

        # Update code via input section
        new_parsed_script['methods'][method] = new_code_block

# Define filenames and paths for consolidated and organized code files
consolidated_file_name = f"{mitigated_base_name}_consolidated{ext}"
consolidated_file_path = os.path.join(mitigated_folder, consolidated_file_name)

# Write the consolidated code sections into a single file
with open(consolidated_file_path, 'w') as file:
    # Write methods in alphabetical order
    for method_name in sorted(new_parsed_script['methods']):
        file.write(new_parsed_script['methods'][method_name] + '\n\n')

# Organize imports and global variables in the consolidated code
organized_fixed_code = organize_imports_and_globals(consolidated_file_path)

# Define filename and path for the organized code file
organized_file_name = f"{mitigated_base_name}_organized{ext}"
organized_file_path = os.path.join(mitigated_folder, organized_file_name)

# Write the organized code to a file
write_to_file(organized_file_path, organized_fixed_code)

# Read the contents of the organized file
with open(organized_file_path, 'r') as file:
    code_content = file.read()

# Use autoimport to fix import issues
fixed_code = autoimport.fix_code(code_content)

# Combine system and user prompts into a message list
refactor_script_user_prompt = refactor_script_user_prompt.format(fixed_code=fixed_code)
refactor_script_messages = [
    {"role": "system", "content": refactor_script_system_prompt},
    {"role": "user", "content": refactor_script_user_prompt}
]

# Create chat completion llama object
refactor_llm_config = create_chat_completion_llm(
    llm,
    refactor_script_messages,
    0.0,
    1,
    0,
    True,
    ["<|endoftext|>"]
)

# Process the streamed output to obtain the adjusted code block
refactor_code_response = process_streamed_output(refactor_llm_config)

# Extract the code block from the AI's response
refactored_code = extract_code_block(refactor_code_response)

# Use autoimport to fix any dangling imports
refactored_code = autoimport.fix_code(refactored_code)

# Define filename and path for the final output file
refactored_file_name = f"{mitigated_base_name}_refactored{ext}"
refactored_file_path = os.path.join(mitigated_folder, refactored_file_name)

# Save the refined code to the final output file
write_to_file(refactored_file_path, refactored_code)

# Perform the final mitigation of the refactored, organized and consolidated code
logger.info(f"Starting final mitigation of refactored code {refactored_file_path}.")
final_mitigated_code_block, passed_scans = run_mitigation_loop(
    mitigation_system_prompt,
    mitigation_user_prompt,
    iteration_allowance,
    base_name,
    llm,
    logger,
    mitigated_folder,
    mitigated_base_name,
    letter_conversion,
    refactored_code,
    "refactored")

# Unit test gateway after passing security and linter scans
if not passed_scans:
    logger.error(f"Issues are still present in {refactored_file_path}. Please revisit code and associated scans.")
else:

    # Define filename and path for the final output file
    final_file_name = f"{mitigated_base_name}_final{ext}"
    final_file_path = os.path.join(mitigated_folder, final_file_name)

    # Save the refined code to the final output file
    write_to_file(final_file_path, final_mitigated_code_block)

    logger.info(f"Generating unit test file to test {final_file_path}.")

    # Get methods from final mitigated file and generate import statements for the programmatically generated unit test
    method_list = get_methods_from_file(final_file_path)
    methods_string = "\n".join(method_list)
    # methods_to_test = "\n".join([f"\t* {method}" for method in method_list if method != 'main'])
    import_list = [f"{generate_import_statement(final_file_path)} import {method}"
                   for method in method_list if method != 'main']
    file_import_string = '\n'.join(import_list)
    # signatures_list = get_methods_with_signatures(final_file_path)
    # signatures_string = '\n'.join(f"\t* {name}: {signature} -> {rtype}" for name, signature, rtype in signatures_list if name != 'main')

    signature_map = {}
    for method_name in method_list:
        signature_map[method_name] = f"{generate_import_statement(final_file_path)} import {method_name}"

    # Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
    final_parsed_script = parse_python_script(final_file_path)

    # Map out the test types for unit test creation
    test_types = {
        'positive': '**Positive Test:** Verifies normal method behavior.',
        'negative': '**Negative Test:** Handles invalid input.',
        'boundary': '**Boundary Test:** Tests a special edge value.'
        }

    # Create a unit test list to store the output code
    unit_test_code_list = []

    for method_name in sorted(final_parsed_script['methods']):
        if method_name != 'main':
            for test_type, description in test_types.items():

                method_code = final_parsed_script['methods'][method_name]

                # Add the original unit test method code block to the
                inline_unit_test_user_prompt = unit_test_user_prompt.format(
                    method_code=method_code,
                    description=description
                )

                # Form the message dictionary
                messages = [
                    {"role": "system", "content": unit_test_system_prompt},
                    {"role": "user", "content": inline_unit_test_user_prompt}
                ]

                # Create chat completion llama object
                functional_unit_test_code_response = create_chat_completion_llm(
                    llm,
                    messages,
                    0.0,
                    1,
                    0,
                    True,
                    ["<|endoftext|>"]
                )

                # Process the streamed response
                unit_test_code_block = process_streamed_output(functional_unit_test_code_response)

                # Extract the code block from the secure code suggestion
                unit_test_code = extract_code_block(unit_test_code_block)

                # Get rid of the "from your module" llm artifact
                unit_test_code = re.sub(r'^from your_module(.*?)\s*$', '', unit_test_code, flags=re.MULTILINE)

                # Implement autoimport
                unit_test_code = autoimport.fix_code(unit_test_code)

                # Define filename and path for the unit test output file
                unit_test_file_name = f"{mitigated_base_name}_{method_name}_unit_test_{test_type}_raw{ext}"
                unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, unit_test_file_name)

                # Create the letter conversion directory within the unit test folder
                os.makedirs(os.path.join(generated_unit_test_dir, letter_conversion), exist_ok=True)

                # Save the refined code to the final output file
                write_to_file(unit_test_file_path, unit_test_code)

                # Prepend the generated import statements again if necessary
                prepend_to_file(unit_test_file_path, signature_map[method_name] + "\n")

                # Append file paths to list
                unit_test_code_list.append(unit_test_file_path)

    # Combine imports and functions
    imports, functions = combine_files(unit_test_code_list)

    # Generate the main method
    main_method = create_main_method(functions.keys())

    # Output: Path to save the combined Python file
    final_unit_test_file_name = f"{mitigated_base_name}_unit_test_final{ext}"
    final_unit_test_path = os.path.join(generated_unit_test_dir, letter_conversion, final_unit_test_file_name)

    # Write the combined Python file
    write_combined_file(final_unit_test_path, imports, functions, main_method)

    # # Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
    # unit_test_parsed_script = parse_python_script(unit_test_file_path)
    #
    # new_unit_test_parsed_script = {
    #     'methods': {}
    # }
    #
    # for section, code in unit_test_parsed_script.items():
    #     logger.info(f"Processing section: {section}...")
    #
    #     if section == 'methods' and unit_test_parsed_script['methods']:
    #         for method, method_code in unit_test_parsed_script['methods'].items():
    #             if method != 'main':
    #                 # Mitigate Code
    #                 new_code_block, passed_scans = run_mitigation_loop(
    #                     mitigation_system_prompt,
    #                     mitigation_user_prompt,
    #                     iteration_allowance,
    #                     base_name,
    #                     llm,
    #                     logger,
    #                     mitigated_folder,
    #                     mitigated_base_name + "_unit_test",
    #                     letter_conversion,
    #                     method_code,
    #                     method
    #                 )
    #
    #                 # Update code via input section
    #                 new_unit_test_parsed_script['methods'][method] = new_code_block
    #     else:
    #         logger.info(f"No code found in section {section}.")
    #
    # # Define filenames and paths for consolidated and organized code files
    # consolidated_unit_test_file_name = f"{mitigated_base_name}_consolidated_unit_test{ext}"
    # consolidated_unit_test_file_path = os.path.join(
    #     generated_unit_test_dir,
    #     letter_conversion,
    #     consolidated_unit_test_file_name
    # )
    #
    # # Write the consolidated code sections into a single file
    # with open(consolidated_unit_test_file_path, 'w') as file:
    #     # Write methods in alphabetical order
    #     for method_name in sorted(new_unit_test_parsed_script['methods']):
    #         file.write(new_unit_test_parsed_script['methods'][method_name] + '\n\n')
    #
    # # Organize imports and global variables in the consolidated code
    # organized_fixed_unit_test_code = organize_imports_and_globals(consolidated_unit_test_file_path)
    #
    # # Define filename and path for the organized code file
    # organized_unit_test_file_name = f"{mitigated_base_name}_organized_unit_test{ext}"
    # organized_unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, organized_unit_test_file_name)
    #
    # # Write the organized code to a file
    # write_to_file(organized_unit_test_file_path, organized_fixed_unit_test_code)
    #
    # # Use autoimport to fix import issues
    # fixed_unit_test_code = autoimport.fix_code(organized_fixed_unit_test_code)
    #
    # # Define filename and path for the final output file
    # final_unit_test_file_name = f"{mitigated_base_name}_unit_test_final{ext}"
    # final_unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, final_unit_test_file_name)
    #
    # # Save the corrected code back to the unit test file
    # write_to_file(final_unit_test_file_path, fixed_unit_test_code)