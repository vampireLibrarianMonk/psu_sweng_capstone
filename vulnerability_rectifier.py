import argparse
import os
import re
import sys
import yaml

import autoimport
from llama_cpp import Llama

from utilities_llm import (setup_logger,
                           get_optimal_gpu_layers,
                           get_block_count_keys,
                           validate_iteration_allowance,
                           parse_python_script, run_mitigation_loop,
                           organize_imports_and_globals, write_to_file, process_streamed_output, extract_code_block,
                           extract_libraries, perform_scans, is_python_file, count_directories_in_path,
                           number_to_excel_column, create_chat_completion_llm, generate_import_statement,
                           get_methods_from_file, get_methods_with_signatures, prepend_to_file, execute_unit_test_file,
                           rename_file, validate_correction_limit, run_method_unit_test_creation_loop
                           )

mitigation_folder = "mitigated_files"

os.makedirs(mitigation_folder, exist_ok=True)

generated_unit_test_dir = "generated_unit_test"

os.makedirs(generated_unit_test_dir, exist_ok=True)

# Specify the path to your GGUF model file
model_path = "models/llama-3.2-3b-instruct-q8_0.gguf"

# Set up argument parser
parser = argparse.ArgumentParser(description='Process a Python file for vulnerability assessment.')
parser.add_argument('file_path', help='Path to the Python file to be analyzed.')
parser.add_argument('iteration_allowance', type=validate_iteration_allowance, help='Allowed number of '
                                                                                'mitigation runs (must be a positive'
                                                                                'integer).')
parser.add_argument('correction_limit', type=validate_correction_limit, help='Allowed number of unit test'
                                                                             'correction mitigation runs (must be a '
                                                                             'positive integer).')

# Parse command-line arguments
args = parser.parse_args()

input_file_path = args.file_path
iteration_allowance = args.iteration_allowance
correction_limit = args.correction_limit

# Get and separate file name into its base name and extension
base_name = os.path.basename(input_file_path)
name, ext = os.path.splitext(base_name)

# Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
parsed_script = parse_python_script(input_file_path)

new_parsed_script = {
    'methods': {}
}

# Get method count of parsed script
method_count = len(parsed_script['methods'].items())

# Define base name for mitigated files
mitigated_base_name = f"{name}_mitigated"

# Get the file count
file_count = count_directories_in_path(os.path.join(mitigation_folder, mitigated_base_name))

# Create folder for mitigated files
letter_conversion = number_to_excel_column(file_count)
mitigated_folder = os.path.join(mitigation_folder, mitigated_base_name, letter_conversion)

# Create the mitigated folder associated with the letter conversion
os.makedirs(mitigated_folder, exist_ok=True)

# Initialize the logger
logger = setup_logger(f"vulnerability_rectifier", letter_conversion, name)

# Load the YAML file
prompt_yaml = "config/prompt.yaml"
logger.info(f"Loading prompt configurations from {prompt_yaml}")
with open(prompt_yaml, 'r') as file:
    data = yaml.safe_load(file)

# Convert the prompts to a dictionary keyed by role
prompts_dict = {prompt['role']: prompt['content'] for prompt in data['prompts']}

# Extract the prompts directly into variables
mitigation_system_prompt = prompts_dict['mitigation_system_prompt']
mitigation_user_prompt = prompts_dict['mitigation_user_prompt']
refactor_script_system_prompt = prompts_dict['refactor_script_system_prompt']
refactor_script_user_prompt = prompts_dict['refactor_script_user_prompt']
unit_test_system_prompt = prompts_dict['unit_test_system_prompt']
unit_test_user_prompt = prompts_dict['unit_test_user_prompt']

# Vet the input file as a python script file
if is_python_file(input_file_path):
    with open(input_file_path, 'r') as file:
        original_code = file.read()
else:
    logger.error(f"{input_file_path} is not a valid Python file.")
    sys.exit(1)

# Alternative way for getting block count using Llama
# Load the model
# llm = Llama(model_path=model_path)

# Access the model's metadata
# metadata = llm.metadata

# Retrieve the block count
# total_layers = int(metadata.get('llama.block_count'))

# Get the total layers from the input model
total_layers = get_block_count_keys(model_path, logger)

# Determine the optimal number of GPU layers to offload
n_gpu_layers = get_optimal_gpu_layers(model_path, total_layers)

# Initialize the Llama model with appropriate settings
llm = Llama(
    model_path=model_path,
    seed=42,  # Fixed seed for reproducibility
    n_ctx=4096, #Set the desired context size here
    use_mmap=True,  # Memory mapping for efficiency
    use_mlock=True,  # Prevent swapping to disk for consistent performance
    n_gpu_layers=n_gpu_layers
)

# Only process the methods that
if parsed_script['methods']:
    logger.info(f"Processing parsed methods:")
    for method, method_code in parsed_script['methods'].items():
        # Mitigate Code
        new_code_block, passed_scans = run_mitigation_loop(
            mitigation_system_prompt,
            mitigation_user_prompt,
            iteration_allowance,
            base_name,
            llm,
            logger,
            mitigated_folder,
            mitigated_base_name,
            letter_conversion,
            method_code,
            method)

        # Update code via input section
        new_parsed_script['methods'][method] = new_code_block

# Define filenames and paths for consolidated and organized code files
consolidated_file_name = f"{mitigated_base_name}_consolidated{ext}"
consolidated_file_path = os.path.join(mitigated_folder, consolidated_file_name)

# Write the consolidated code sections into a single file
with open(consolidated_file_path, 'w') as file:
    # Write methods in alphabetical order
    for method_name in sorted(new_parsed_script['methods']):
        file.write(new_parsed_script['methods'][method_name] + '\n\n')

# Organize imports and global variables in the consolidated code
organized_fixed_code = organize_imports_and_globals(consolidated_file_path)

# Define filename and path for the organized code file
organized_file_name = f"{mitigated_base_name}_organized{ext}"
organized_file_path = os.path.join(mitigated_folder, organized_file_name)

# Write the organized code to a file
write_to_file(organized_file_path, organized_fixed_code)

# Read the contents of the organized file
with open(organized_file_path, 'r') as file:
    code_content = file.read()

# Use autoimport to fix import issues
fixed_code = autoimport.fix_code(code_content)

# Combine system and user prompts into a message list
refactor_script_user_prompt = refactor_script_user_prompt.format(fixed_code=fixed_code)
refactor_script_messages = [
    {"role": "system", "content": refactor_script_system_prompt},
    {"role": "user", "content": refactor_script_user_prompt}
]

# Create chat completion llama object
refactor_llm_config = create_chat_completion_llm(
    llm,
    refactor_script_messages,
    0.0,
    1,
    0,
    True,
    ["<|endoftext|>"]
)

# Process the streamed output to obtain the adjusted code block
refactor_code_response = process_streamed_output(refactor_llm_config)

# Extract the code block from the AI's response
refactored_code = extract_code_block(refactor_code_response)

# Use autoimport to fix any dangling imports
refactored_code = autoimport.fix_code(refactored_code)

# Define filename and path for the final output file
refactored_file_name = f"{mitigated_base_name}_refactored{ext}"
refactored_file_path = os.path.join(mitigated_folder, refactored_file_name)

# Save the refined code to the final output file
write_to_file(refactored_file_path, refactored_code)

# Perform the final mitigation of the refactored, organized and consolidated code
logger.info(f"Starting final mitigation of refactored code {refactored_file_path}.")
final_mitigated_code_block, passed_scans = run_mitigation_loop(
    mitigation_system_prompt,
    mitigation_user_prompt,
    iteration_allowance,
    base_name,
    llm,
    logger,
    mitigated_folder,
    mitigated_base_name,
    letter_conversion,
    refactored_code,
    "refactored")

# Unit test gateway after passing security and linter scans
if not passed_scans:
    logger.error(f"Issues are still present in {refactored_file_path}. Please revisit code and associated scans.")
else:

    # Define filename and path for the final output file
    final_file_name = f"{mitigated_base_name}_final{ext}"
    final_file_path = os.path.join(mitigated_folder, final_file_name)

    # Save the refined code to the final output file
    write_to_file(final_file_path, final_mitigated_code_block)

    logger.info(f"Generating unit test file to test {final_file_path}.")

    # Add the original unit test method code block to the
    unit_test_user_prompt += "\n\n" + final_mitigated_code_block

    # Form the message dictionary
    messages = [
        {"role": "system", "content": unit_test_system_prompt},
        {"role": "user", "content": unit_test_user_prompt}
    ]

    # Create chat completion llama object
    functional_unit_test_code_response = create_chat_completion_llm(
        llm,
        messages,
        0.0,
        1,
        0,
        True,
        ["<|endoftext|>"]
    )

    # Process the streamed response
    unit_test_code_block = process_streamed_output(functional_unit_test_code_response)

    # Extract the code block from the secure code suggestion
    unit_test_code = extract_code_block(unit_test_code_block)

    # Get rid of the "from your module" llm artifact
    unit_test_code = re.sub(r'^from your_module(.*?)\s*$', '', unit_test_code, flags=re.MULTILINE)

    # Define filename and path for the unit test output file
    unit_test_file_name = f"{mitigated_base_name}_unit_test_raw{ext}"
    unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, unit_test_file_name)

    os.makedirs(os.path.join(generated_unit_test_dir, letter_conversion), exist_ok=True)

    # Save the refined code to the final output file
    write_to_file(unit_test_file_path, unit_test_code)

    # Get methods from final mitigated file and generate import statements for the programmatically generated unit test
    method_list = get_methods_from_file(final_file_path)
    methods_string = "\n".join(method_list)
    import_list = [f"{generate_import_statement(final_file_path)} import {method}"
                   for method in method_list if method != 'main']
    import_string = '\n'.join(import_list)
    # signatures_list = get_methods_with_signatures(final_file_path)
    # signatures_string = '\n'.join(f"{name}: {signature} -> {rtype}" for name, signature, rtype in signatures_list)

    # Prepend the generated import statements again if necessary
    prepend_to_file(unit_test_file_path, import_string + "\n")

    # Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
    unit_test_parsed_script = parse_python_script(unit_test_file_path)

    new_unit_test_parsed_script = {
        'global_variables': '',
        'methods': {},
        'main_script': ''
    }

    for section, code in unit_test_parsed_script.items():
        logger.info(f"Processing section: {section}...")

        if section == 'methods' and unit_test_parsed_script['methods']:
            for method, method_code in unit_test_parsed_script['methods'].items():
                if method != 'main':
                    # Mitigate Code
                    new_code_block, passed_scans = run_mitigation_loop(
                        mitigation_system_prompt,
                        mitigation_user_prompt,
                        iteration_allowance,
                        base_name,
                        llm,
                        logger,
                        mitigated_folder,
                        mitigated_base_name + "_unit_test",
                        letter_conversion,
                        method_code,
                        method
                    )

                    # Update code via input section
                    new_unit_test_parsed_script['methods'][method] = new_code_block
        else:
            logger.info(f"No code found in section {section}.")

    # Define filenames and paths for consolidated and organized code files
    consolidated_unit_test_file_name = f"{mitigated_base_name}_consolidated_unit_test{ext}"
    consolidated_unit_test_file_path = os.path.join(
        generated_unit_test_dir,
        letter_conversion,
        consolidated_unit_test_file_name
    )

    # Write the consolidated code sections into a single file
    with open(consolidated_unit_test_file_path, 'w') as file:
        # Write methods in alphabetical order
        for method_name in sorted(new_unit_test_parsed_script['methods']):
            file.write(new_unit_test_parsed_script['methods'][method_name] + '\n\n')

    # Organize imports and global variables in the consolidated code
    organized_fixed_unit_test_code = organize_imports_and_globals(consolidated_unit_test_file_path)

    # Define filename and path for the organized code file
    organized_unit_test_file_name = f"{mitigated_base_name}_organized_unit_test{ext}"
    organized_unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, organized_unit_test_file_name)

    # Write the organized code to a file
    write_to_file(organized_unit_test_file_path, organized_fixed_unit_test_code)

    # Use autoimport to fix import issues
    fixed_unit_test_code = autoimport.fix_code(organized_fixed_unit_test_code)

    # Define filename and path for the final output file
    final_unit_test_file_name = f"{mitigated_base_name}_unit_test_final{ext}"
    final_unit_test_file_path = os.path.join(generated_unit_test_dir, letter_conversion, final_unit_test_file_name)

    # Save the corrected code back to the unit test file
    write_to_file(final_unit_test_file_path, fixed_unit_test_code)