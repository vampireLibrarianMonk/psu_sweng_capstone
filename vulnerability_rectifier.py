import argparse
import os
import re
import sys

import autoimport
from llama_cpp import Llama

from utilities_llm import (setup_logger,
                           get_optimal_gpu_layers,
                           get_block_count_keys,
                           validate_iteration_allowance,
                           parse_python_script, run_mitigation_loop,
                           organize_imports_and_globals, write_to_file, process_streamed_output, extract_code_block,
                           extract_libraries, perform_scans, is_python_file, count_directories_in_path,
                           number_to_excel_column, create_chat_completion_llm, generate_import_statement,
                           get_methods_from_file, get_methods_with_signatures, prepend_to_file, execute_unit_test_file,
                           rename_file, validate_correction_limit, run_method_unit_test_creation_loop
                           )

mitigation_folder = "mitigated_files"

os.makedirs(mitigation_folder, exist_ok=True)

generated_unit_test_dir = "generated_unit_test"

os.makedirs(generated_unit_test_dir, exist_ok=True)

# Specify the path to your GGUF model file
model_path = "models/llama-3.2-3b-instruct-q8_0.gguf"

# Set up argument parser
parser = argparse.ArgumentParser(description='Process a Python file for vulnerability assessment.')
parser.add_argument('file_path', help='Path to the Python file to be analyzed.')
parser.add_argument('iteration_allowance', type=validate_iteration_allowance, help='Allowed number of '
                                                                                'mitigation runs (must be a positive'
                                                                                'integer).')
parser.add_argument('correction_limit', type=validate_correction_limit, help='Allowed number of unit test'
                                                                             'correction mitigation runs (must be a '
                                                                             'positive integer).')

# Parse command-line arguments
args = parser.parse_args()

input_file_path = args.file_path
iteration_allowance = args.iteration_allowance
correction_limit = args.correction_limit

# Vet the input file as a python script file
if is_python_file(input_file_path):
    with open(input_file_path, 'r') as file:
        original_code = file.read()
else:
    print(f"{input_file_path} is not a valid Python file.")
    sys.exit(1)

# Get and separate file name into its base name and extension
base_name = os.path.basename(input_file_path)
name, ext = os.path.splitext(base_name)

# Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
parsed_script = parse_python_script(input_file_path)

new_parsed_script = {
    'global_variables': '',
    'methods': {},
    'main_script': ''
}

# Get method count of parsed script
method_count = len(parsed_script['methods'].items())

# Define base name for mitigated files
mitigated_base_name = f"{name}_mitigated"

# Get the file count
file_count = count_directories_in_path(os.path.join(mitigation_folder, mitigated_base_name))

# Create folder for mitigated files
associated_letter_conversion = number_to_excel_column(file_count)
mitigated_folder = os.path.join(mitigation_folder, mitigated_base_name, associated_letter_conversion)

# Initialize the logger
logger = setup_logger(f"vulnerability_rectifier", associated_letter_conversion, name)

os.makedirs(mitigated_folder, exist_ok=True)

# Alternative way for getting block count using Llama
# Load the model
# llm = Llama(model_path=model_path)

# Access the model's metadata
# metadata = llm.metadata

# Retrieve the block count
# total_layers = int(metadata.get('llama.block_count'))

# Get the total layers from the input model
total_layers = get_block_count_keys(model_path, logger)

# Determine the optimal number of GPU layers to offload
n_gpu_layers = get_optimal_gpu_layers(model_path, total_layers)

# Initialize the Llama model with appropriate settings
llm = Llama(
    model_path=model_path,
    seed=42,  # Fixed seed for reproducibility
    n_ctx=4096, #Set the desired context size here
    use_mmap=True,  # Memory mapping for efficiency
    use_mlock=True,  # Prevent swapping to disk for consistent performance
    n_gpu_layers=n_gpu_layers
)

for section, code in parsed_script.items():
    logger.info(f"Processing section: {section}...")

    if section == 'methods' and parsed_script['methods']:
        for method, method_code in parsed_script['methods'].items():
            # Mitigate Code
            new_code_block = run_mitigation_loop(
                iteration_allowance,
                base_name,
                llm,
                logger,
                mitigated_folder,
                mitigated_base_name,
                associated_letter_conversion,
                method_code,
                method)

            # Update code via input section
            new_parsed_script['methods'][method] = new_code_block

    elif section != 'main_script' and parsed_script[section]:
        new_code_block = run_mitigation_loop(
            iteration_allowance,
            base_name,
            llm,
            logger,
            mitigated_folder,
            mitigated_base_name,
            associated_letter_conversion,
            code,
            section)

        # Update code via input section
        new_parsed_script[section] = new_code_block

    else:
        logger.info(f"No code found in section {section}.")

# Define filenames and paths for consolidated and organized code files
consolidated_file_name = f"{mitigated_base_name}_consolidated{ext}"
consolidated_file_path = os.path.join(mitigated_folder, consolidated_file_name)

# Write the consolidated code sections into a single file
with open(consolidated_file_path, 'w') as file:
    # Write global variables section if it exists
    if new_parsed_script['global_variables']:
        file.write(new_parsed_script['global_variables'] + '\n\n')

    # Write methods in alphabetical order
    for method_name in sorted(new_parsed_script['methods']):
        file.write(new_parsed_script['methods'][method_name] + '\n\n')

    # Write main script section if it exists
    if new_parsed_script['main_script']:
        file.write(new_parsed_script['main_script'] + '\n')

# Organize imports and global variables in the consolidated code
organized_fixed_code = organize_imports_and_globals(consolidated_file_path)

# Define filename and path for the organized code file
organized_file_name = f"{mitigated_base_name}_organized{ext}"
organized_file_path = os.path.join(mitigated_folder, organized_file_name)

# Write the organized code to a file
write_to_file(organized_file_path, organized_fixed_code)

# Read the contents of the organized file
with open(organized_file_path, 'r') as file:
    code_content = file.read()

# Use autoimport to fix import issues
fixed_code = autoimport.fix_code(code_content)

# Prepare the system prompt for the AI assistant
refactor_script_system_prompt = (
    "You are an AI programming assistant proficient in Python application development. Your expertise includes "
    "identifying and refactoring code to enhance security, readability, and efficiency, while adhering to best "
    "practices. Your guidance should be concise, actionable, and prioritize abstraction when reviewing and "
    "refactoring code."
)

# Prepare the user prompt with the code to be reviewed
refactor_script_user_prompt = (
    f"""
    Please review and refactor the following Python code. Focus on:

    1. Abstracting redundant logic to improve maintainability.
    2. Implementing structured error handling to manage unexpected input types:
       - Address exceptions specific to the method's functionality first.
       - Handle exceptions from associated libraries next.
       - Finally, address general exceptions, preserving their original types and messages.
    3. Ensuring a main method is implemented for standalone running capability:
       - The `main` method should initialize and orchestrate the execution of the program's functionality.
       - Include appropriate logging within the `main` method to track execution and identify issues.
       - Ensure the `main` method is invoked when the script is executed directly.

    Avoid altering behavior or introducing additional variables. Use concise comments to explain critical modifications:
    ```python
    {fixed_code}
    ```
    """
)

# Combine system and user prompts into a message list
refactor_script_messages = [
    {"role": "system", "content": refactor_script_system_prompt},
    {"role": "user", "content": refactor_script_user_prompt}
]

# Create chat completion llama object
refactor_llm_config = create_chat_completion_llm(
    llm,
    refactor_script_messages,
    0.0,
    1,
    0,
    True,
    ["<|endoftext|>"]
)

# Process the streamed output to obtain the adjusted code block
refactor_code_response = process_streamed_output(refactor_llm_config)

# Extract the code block from the AI's response
refactored_code = extract_code_block(refactor_code_response)

# Use autoimport to fix any dangling imports
refactored_code = autoimport.fix_code(refactored_code)

# Define filename and path for the final output file
final_file_name = f"{mitigated_base_name}_refactored{ext}"
final_file_path = os.path.join(mitigated_folder, final_file_name)

# Save the refined code to the final output file
write_to_file(final_file_path, refactored_code)

# Extract the libraries from the mitigated code
extracted_libraries = extract_libraries(refactored_code)

# Perform vulnerability scans again
(bandit_issues, dodgy_issues, semgrep_issues, mypy_issues) = perform_scans(
                                                                final_file_path,
                                                                associated_letter_conversion,
                                                                extracted_libraries,
                                                                logger
                                                                )

needs_mitigation = (bandit_issues == '' and
                    dodgy_issues == 'No issues found.' and
                    semgrep_issues == 'No issues found.' and
                    mypy_issues == 'No issues found.')


# Peform the final mitigation of the refactored, organized and consolidated code
if not needs_mitigation:
    final_mitigated_code_block = run_mitigation_loop(
        iteration_allowance,
        base_name,
        llm,
        logger,
        mitigated_folder,
        mitigated_base_name,
        associated_letter_conversion,
        refactored_code,
        "final")

# Define filename and path for the final output file
final_file_name = f"{mitigated_base_name}_final{ext}"
final_file_path = os.path.join(mitigated_folder, final_file_name)

# Save the refined code to the final output file
write_to_file(final_file_path, refactored_code)

print("COMPLETE")

#     # Get methods from final mitigated file and generate import statements for the programmatically generated unit test
#     method_list = get_methods_from_file(final_mitigated_file_path)
#     methods_string = "\n".join(method_list)
#     import_list = [f"{generate_import_statement(final_mitigated_file_path)} import {method}" for method in method_list]
#     import_string = '\n'.join(import_list)
#     # signatures_list = get_methods_with_signatures(final_mitigated_file_path)
#     # signatures_string = '\n'.join(f"{name}: {signature} -> {rtype}" for name, signature, rtype in signatures_list)

# if vulnerability_gate:
#     logger.info(f"Generating unit test file to test {input_file_path} and {final_mitigated_file_path}.")
#
#     # Read the specified file and use ast to parse it into a map for quicker analysis and mitigation
#     mitigated_parsed_script = parse_python_script(final_mitigated_file_path)
#
#     unit_test_parsed_script = {
#         'global_variables': '',
#         'methods': {},
#         'main_script': ''
#     }
#
#     for section, code in mitigated_parsed_script.items():
#         logger.info(f"Processing section: {section}...")
#
#         os.makedirs(os.path.join(generated_unit_test_dir, associated_letter_conversion), exist_ok=True)
#
#         if section == 'methods' and mitigated_parsed_script['methods']:
#             for method, method_code in mitigated_parsed_script['methods'].items():
#                 # Mitigate Code
#                 new_code_block = run_method_unit_test_creation_loop(
#                     correction_limit,
#                     base_name,
#                     llm,
#                     logger,
#                     generated_unit_test_dir,
#                     mitigated_base_name,
#                     associated_letter_conversion,
#                     method_code,
#                     method,
#                 f"{generate_import_statement(final_mitigated_file_path)} import {method}")
#
#                 # Update code via input section
#                 unit_test_parsed_script['methods'][method] = new_code_block
#
#         elif section != 'main_script' and mitigated_parsed_script[section]:
#             pass
#
#         else:
#             logger.info(f"No code found in section {section}.")